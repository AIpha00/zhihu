# zhihu
爬虫模拟登陆知乎网站并抓取首页的数据入库
前段时间一直在忙毕业的事情，所以很久很久没有更新了。最近呢，又在重新找工作，不得不说北京还是不太好混啊。
好了，我们还是说回正题，之前一直想解决知乎的模拟登陆。奈何一直没有时间，正好最近没有面试闲的慌，我们来讲讲如何破解知乎的反爬，并且实现首页的抓取。
我们先抓包看看。
发现我们点击登陆按钮时，知乎后台会post这个（https://www.zhihu.com/api/v3/oauth/sign_in）请求出去，formdata即为下图那般模样，看见这个想都不用想，开始枯燥的js调试吧。

好的，打开chrome的全局搜索，用sign_in作为搜索的关键字，开始吧

熟悉前端的朋友可以看出，这个方法即是构造登陆验证的URL，这里的body可以看出有非常大的问题在！我们在这里打赏断点，开始调试，
